{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8d228c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "모든 이미지 resize 완료!\n",
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "라벨:  0\n",
      "x_train shape: (310, 28, 28, 3)\n",
      "y_train shape: (310,)\n",
      "x_test shape: (310, 28, 28, 3)\n",
      "y_test shape: (310,)\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 32)                25632     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 30,819\n",
      "Trainable params: 30,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.1000 - accuracy: 0.3355\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0922 - accuracy: 0.4097\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0877 - accuracy: 0.4129\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0838 - accuracy: 0.3645\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0650 - accuracy: 0.5581\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0468 - accuracy: 0.5097\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0274 - accuracy: 0.5000\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0050 - accuracy: 0.6903\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9777 - accuracy: 0.6484\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9356 - accuracy: 0.7903\n",
      "10/10 - 0s - loss: 1.1991 - accuracy: 0.4226\n",
      "test_loss: 1.1990816593170166 \n",
      "test_accuracy: 0.42258065938949585\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "image_dir_path2 = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "resize_images(image_dir_path2)\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "image_dir_path2 = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/rock\"\n",
    "resize_images(image_dir_path)\n",
    "resize_images(image_dir_path2)\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "image_dir_path2 = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/paper\"\n",
    "resize_images(image_dir_path)\n",
    "resize_images(image_dir_path2)\n",
    "\n",
    "print(\"모든 이미지 resize 완료!\") # 이미지 resize를 했다.\n",
    "\n",
    "\n",
    "def load_data(img_path, number_of_data=310):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "x_train_reshaped = x_train_norm.reshape(-1,28,28,3)\n",
    "\n",
    "image_test_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\"\n",
    "(x_test, y_test)=load_data(image_test_dir_path)\n",
    "\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "x_test_reshaped=x_test_norm.reshape( -1, 28, 28, 3)\n",
    "\n",
    "plt.imshow(x_train[0])\n",
    "print('라벨: ', y_train[0])\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))\n",
    "\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))\n",
    "\n",
    "n_channel_1=16\n",
    "n_channel_2=32\n",
    "n_dense=32\n",
    "n_train_epoch=10\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_reshaped, y_train, epochs=n_train_epoch)\n",
    "\n",
    "# 모델 시험\n",
    "test_loss, test_accuracy = model.evaluate(x_test_norm, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2371ffbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
